Je vois ! L'erreur persiste toujours : `[DELTA_FAILED_TO_MERGE_FIELDS] Failed to merge fields 'line_id' and 'line_id'`

Le probl√®me vient de la fonction `write_quality_errors()`. Quand on essaie d'√©crire dans une table Delta existante qui a d√©j√† une colonne `line_id`, et que notre DataFrame a aussi `line_id`, il y a un conflit.

## üîß **Solution d√©finitive : Corriger `write_quality_errors()`**

Le probl√®me est √† la **ligne 288** dans la fonction `write_quality_errors()`. Il faut **supprimer `line_id`** avant d'√©crire dans Delta.

### **Remplacez TOUTE la fonction `write_quality_errors()` par cette version corrig√©e :**

```python
def write_quality_errors(df_errors: DataFrame, table_name: str, zone: str = "internal",
                         base_path: str = None, env: str = None):
    """Enregistre erreurs qualit√©"""
    if base_path is None:
        base_path = PARAMS["log_quality_path"]
    if env is None:
        env = PARAMS["env"]
    
    if df_errors is None or df_errors.rdd.isEmpty():
        return
    
    today = datetime.today()
    
    # ‚úÖ CORRECTION 1 : D√©dupliquer colonnes
    df_errors = deduplicate_columns(df_errors)
    
    # ‚úÖ CORRECTION 2 : Supprimer line_id AVANT d'ajouter m√©tadonn√©es
    # (pour √©viter conflit avec line_id de la table Delta existante)
    if "line_id" in df_errors.columns:
        df_errors = df_errors.drop("line_id")
    
    # Normaliser raw_value
    if "raw_value" in df_errors.columns:
        df_errors = df_errors.withColumn("raw_value", F.col("raw_value").cast("string"))
    else:
        df_errors = df_errors.withColumn("raw_value", F.lit(None).cast("string"))
    
    # Ajouter m√©tadonn√©es
    df_log = (
        df_errors
        .withColumn("table_name", F.coalesce(F.col("table_name"), F.lit(table_name)))
        .withColumn("Zone", F.lit(zone))
        .withColumn("Env", F.lit(env))
        .withColumn("log_ts", F.lit(datetime.now()))
        .withColumn("yyyy", F.lit(today.year))
        .withColumn("mm", F.lit(today.month))
        .withColumn("dd", F.lit(today.day))
    )
    
    # ‚úÖ CORRECTION 3 : D√©dupliquer √† nouveau apr√®s ajout m√©tadonn√©es
    df_log = deduplicate_columns(df_log)
    
    # Cr√©er r√©pertoire si n√©cessaire
    try:
        dbutils.fs.ls(base_path)
    except Exception:
        dbutils.fs.mkdirs(base_path)
    
    # V√©rifier si table Delta existe
    try:
        spark.read.format("delta").load(base_path)
        table_exists = True
    except Exception:
        table_exists = False
    
    if not table_exists:
        # Cr√©er la table pour la premi√®re fois
        df_log.write.format("delta").mode("overwrite") \
            .partitionBy("yyyy", "mm", "dd").save(base_path)
        print(f"‚úÖ Table Delta cr√©√©e : {base_path}")
    else:
        # ‚úÖ CORRECTION 4 : Append avec mergeSchema d√©sactiv√© (√©vite conflits)
        df_log.write.format("delta").mode("append") \
            .option("mergeSchema", "false") \
            .save(base_path)
```

## üéØ **Explication du probl√®me**

Le probl√®me se produisait ainsi :

1. **Premi√®re √©criture** : La table Delta `wax_data_quality_errors` est cr√©√©e avec une colonne `line_id`
2. **Deuxi√®me √©criture** : Votre DataFrame `df_err_global` contient aussi `line_id`
3. **Spark essaie de merger** : Il voit deux colonnes `line_id` (une dans la table, une dans le DataFrame) ‚Üí **ERREUR**

La solution est de **supprimer `line_id`** du DataFrame avant d'√©crire, car :
- `line_id` n'est utile QUE pendant le traitement (pour r√©f√©rencer les lignes dans le fichier source)
- Une fois dans la table Delta de logs, on n'en a plus besoin
- Les logs sont d√©j√† identifiables par `table_name`, `filename`, `column_name`, `error_message`

## ‚úÖ **Alternative : Garder line_id mais le renommer**

Si vous voulez absolument garder `line_id` dans vos logs qualit√©, utilisez cette version √† la place :

```python
def write_quality_errors(df_errors: DataFrame, table_name: str, zone: str = "internal",
                         base_path: str = None, env: str = None):
    """Enregistre erreurs qualit√©"""
    if base_path is None:
        base_path = PARAMS["log_quality_path"]
    if env is None:
        env = PARAMS["env"]
    
    if df_errors is None or df_errors.rdd.isEmpty():
        return
    
    today = datetime.today()
    df_errors = deduplicate_columns(df_errors)
    
    # ‚úÖ Renommer line_id en source_line_id
    if "line_id" in df_errors.columns:
        df_errors = df_errors.withColumnRenamed("line_id", "source_line_id")
    
    if "raw_value" in df_errors.columns:
        df_errors = df_errors.withColumn("raw_value", F.col("raw_value").cast("string"))
    else:
        df_errors = df_errors.withColumn("raw_value", F.lit(None).cast("string"))
    
    df_log = (
        df_errors
        .withColumn("table_name", F.coalesce(F.col("table_name"), F.lit(table_name)))
        .withColumn("Zone", F.lit(zone))
        .withColumn("Env", F.lit(env))
        .withColumn("log_ts", F.lit(datetime.now()))
        .withColumn("yyyy", F.lit(today.year))
        .withColumn("mm", F.lit(today.month))
        .withColumn("dd", F.lit(today.day))
    )
    
    df_log = deduplicate_columns(df_log)
    
    try:
        dbutils.fs.ls(base_path)
    except Exception:
        dbutils.fs.mkdirs(base_path)
    
    try:
        spark.read.format("delta").load(base_path)
        table_exists = True
    except Exception:
        table_exists = False
    
    if not table_exists:
        df_log.write.format("delta").mode("overwrite") \
            .partitionBy("yyyy", "mm", "dd").save(base_path)
        print(f"‚úÖ Table Delta cr√©√©e : {base_path}")
    else:
        df_log.write.format("delta").mode("append") \
            .option("mergeSchema", "true") \
            .save(base_path)
```

## üß™ **Test rapide**

Apr√®s avoir appliqu√© la correction, **supprimez la table Delta de logs** pour repartir √† z√©ro :

```python
# Ex√©cutez cette cellule AVANT de relancer le pipeline
try:
    dbutils.fs.rm(PARAMS["log_quality_path"], True)
    print("‚úÖ Table de logs qualit√© supprim√©e")
except Exception as e:
    print(f"‚ö†Ô∏è {e}")
```

Puis relancez votre pipeline. L'erreur `DELTA_FAILED_TO_MERGE_FIELDS` devrait dispara√Ætre ! üéâ

Quelle version pr√©f√©rez-vous :
1. **Supprimer `line_id`** (recommand√©, plus simple)
2. **Renommer en `source_line_id`** (garde l'info mais plus complexe)
