# Databricks notebook source
# MAGIC %md
# MAGIC # WAX Pipeline - Point d'entr√©e principal
# MAGIC
# MAGIC Pipeline ETL pour ingestion de donn√©es CSV/Excel dans Delta Lake
# MAGIC
# MAGIC **Architecture**: Databricks Asset Bundle
# MAGIC
# MAGIC ---

# COMMAND ----------

# MAGIC %md
# MAGIC ## 1. Param√®tres du Notebook (Widgets)

# COMMAND ----------

# Cr√©ation des widgets Databricks
dbutils.widgets.text("zip_path", "dbfs:/FileStore/tables/site_20251201_120001.zip", "üì¶ Source ZIP")
dbutils.widgets.text("excel_path", "dbfs:/FileStore/tables/waxsite_config.xlsx", "üìë Config Excel")
dbutils.widgets.text("extract_dir", "dbfs:/tmp/unzipped_wax_csvs", "üìÇ Extract Dir")
dbutils.widgets.text("log_exec_path", "/mnt/logs/wax_execution_logs_delta", "üìù Logs Exec")
dbutils.widgets.text("log_quality_path", "/mnt/logs/wax_data_quality_errors", "üö¶ Logs Quality")
dbutils.widgets.text("env", "dev", "üåç Environment")
dbutils.widgets.text("version", "v1", "üîñ Version")

# COMMAND ----------

# MAGIC %md
# MAGIC ## 2. Import du module WAX Pipeline

# COMMAND ----------

# Installation du package (si n√©cessaire)
# %pip install /dbfs/jfrog/wax_pipeline-1.0.0-py3-none-any.whl

# Import du module principal
from src.main import main
from src.config import get_config

# COMMAND ----------

# MAGIC %md
# MAGIC ## 3. Configuration

# COMMAND ----------

# R√©cup√©ration de la configuration depuis les widgets
params = get_config(dbutils)

print("üì• Configuration charg√©e:")
for k, v in params.items():
    print(f"  {k}: {v}")

# COMMAND ----------

# MAGIC %md
# MAGIC ## 4. Ex√©cution du Pipeline

# COMMAND ----------

import time
start_time = time.time()

try:
    # Ex√©cution du pipeline principal
    print("üöÄ D√©marrage du WAX Pipeline...")
    main()

    duration = round(time.time() - start_time, 2)
    print(f"‚úÖ Pipeline termin√© avec succ√®s en {duration}s")

except Exception as e:
    duration = round(time.time() - start_time, 2)
    print(f"‚ùå Erreur lors de l'ex√©cution du pipeline apr√®s {duration}s")
    print(f"Erreur: {str(e)}")

    # Log de l'erreur
    import traceback
    traceback.print_exc()

    # √âchec du notebook
    dbutils.notebook.exit(f"FAILED: {str(e)}")

# COMMAND ----------

# MAGIC %md
# MAGIC ## 5. R√©sultats et Dashboards

# COMMAND ----------

# Affichage des logs d'ex√©cution
try:
    log_exec = spark.read.format("delta").load(params["log_exec_path"])
    display(
        log_exec
        .select("tableName", "fileName", "ingestionMode", "status", "errorCount", "env", "duration", "ts")
        .orderBy("ts", ascending=False)
        .limit(50)
    )
except Exception as e:
    print(f"‚ö†Ô∏è Impossible de charger les logs d'ex√©cution: {e}")

# COMMAND ----------

# Affichage des logs de qualit√©
try:
    log_quality = spark.read.format("delta").load(params["log_quality_path"])
    display(
        log_quality
        .select("table_name", "filename", "line_id", "column_name", "error_message", "error_count", "zone", "env", "log_ts")
        .orderBy("log_ts", ascending=False)
        .limit(100)
    )
except Exception as e:
    print(f"‚ö†Ô∏è Impossible de charger les logs de qualit√©: {e}")

# COMMAND ----------

# MAGIC %md
# MAGIC ## 6. Statistiques globales

# COMMAND ----------

# Statistiques d'ex√©cution
try:
    stats = log_exec.groupBy("status", "env").count()
    display(stats)
except:
    pass

# COMMAND ----------

dbutils.notebook.exit("SUCCESS")
