"""
Module file_processor.py
------------------------
Gestion du traitement des fichiers ZIP et CSV :
- Compatible Databricks et ex√©cution locale
- Liste des fichiers et extraction des donn√©es
"""

import os
from pyspark.sql import SparkSession


# =========================================================
# üîß D√©tection environnement
# =========================================================
def is_databricks():
    return "DATABRICKS_RUNTIME_VERSION" in os.environ


# =========================================================
# üìÇ Liste les fichiers (compatible local + Databricks)
# =========================================================
def list_files(extract_dir: str, spark: SparkSession = None):
    """
    Liste les fichiers dans un dossier local ou sur Databricks.
    - Si Databricks : utilise dbutils.fs.ls()
    - Si local : utilise os.listdir()
    """
    if is_databricks():
        try:
            from pyspark.dbutils import DBUtils
            dbutils = DBUtils(spark)
            files = [f.path for f in dbutils.fs.ls(extract_dir)]
            print(f"üìÇ Fichiers d√©tect√©s sur DBFS : {len(files)} trouv√©s")
            return files
        except Exception as e:
            print(f"‚ö†Ô∏è Erreur DBFS ({e}) ‚Üí fallback local")

    # Mode local
    if os.path.exists(extract_dir):
        files = [os.path.join(extract_dir, f) for f in os.listdir(extract_dir)]
        print(f"üìÇ Fichiers locaux d√©tect√©s : {len(files)} trouv√©s")
        return files
    else:
        print(f"‚ùå Dossier inexistant : {extract_dir}")
        return []


# =========================================================
# üßæ Exemple d'utilisation
# =========================================================
def process_files(spark, params):
    extract_dir = params["extract_dir"]

    # Cr√©ation du dossier si inexistant
    if not os.path.exists(extract_dir) and not is_databricks():
        print(f"üìÅ Cr√©ation du dossier : {extract_dir}")
        os.makedirs(extract_dir, exist_ok=True)

    all_files = list_files(extract_dir, spark)
    if not all_files:
        print("‚ö†Ô∏è Aucun fichier trouv√© √† traiter.")
    else:
        print(f"‚úÖ {len(all_files)} fichier(s) pr√™t(s) √† √™tre trait√©(s).")
